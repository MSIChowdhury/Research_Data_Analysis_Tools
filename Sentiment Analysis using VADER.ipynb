{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104e3cde",
   "metadata": {},
   "source": [
    "This notebook contains the Python code to run sentiment analysis on column(s) of texts. I prepared this code to be be reused in future scientific studies for both myself and anyone who finds it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba3e5a",
   "metadata": {},
   "source": [
    "Import the NLTK library and download files for stopwords, punctuations and VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') # List of punctuations\n",
    "nltk.download('stopwords') # List of stopwords \n",
    "nltk.download('vader_lexicon') # VADER files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada89175",
   "metadata": {},
   "source": [
    "Load up the CSV file as per the comments into a Pandas Dataframe. The data is cleaned for:\n",
    "\n",
    "1. Uppercase characters\n",
    "2. Numeric characters\n",
    "3. Stopwords and punctuation marks (i.e period(.), commas(,))\n",
    "\n",
    "The sentiment of the texts are then analyzed using VADER to print out the sentiment polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "# Define stopwords for removal\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function cleans text data by handling potential non-string values,\n",
    "    lowercasing, removing punctuation, and removing stopwords.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        # Handle non-string values gracefully (e.g., return empty string)\n",
    "        return \"\"\n",
    "\n",
    "    # Lowercase conversion\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in punctuation])\n",
    "\n",
    "    # Tokenization (splitting into words)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Join back into a cleaned text string\n",
    "    cleaned_text = ' '.join(filtered_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Replace 'data.csv' with the path to your actual CSV file\n",
    "# Replace 'text_column' with the name of the column containing the text data\n",
    "df = pd.read_csv('data.csv')\n",
    "text_column = 'text_column'\n",
    "\n",
    "# Clean text data, handling potential non-string values\n",
    "df[text_column] = df[text_column].apply(clean_text)\n",
    "\n",
    "# Create sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Add new columns for sentiment scores\n",
    "df['sentiment_polarity'] = df[text_column].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Print or use the DataFrame with sentiment scores as needed\n",
    "print(df['sentiment_polarity'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
